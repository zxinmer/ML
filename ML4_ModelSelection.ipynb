{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c21b87bd",
   "metadata": {},
   "source": [
    "# 학습 /테스트 데이터 셋 분리하지 않고 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74bb3098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_cld = DecisionTreeClassifier()\n",
    "\n",
    "train_data = iris_data.data\n",
    "train_label = iris_data.target\n",
    "\n",
    "#학습 수행\n",
    "dt_clf.fit(train_data , train_label)\n",
    "\n",
    "#테스트\n",
    "pred = dt_clf.predict(train_data)\n",
    "print('예측 정확도 :', accuracy_score(train_label,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b13b5a9",
   "metadata": {},
   "source": [
    "# 분리하고 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d486433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 1 0 1 2 1 1 0 0 2 0 0 0 0 0 1 1 0 2 1 0 0 2 1 0 2 1 2 0 2 0 0 1\n",
      " 2 1 1 0 2 1 0 2 1 1 2 1 2 1 2 2 0 0 2 2 0 1 2 1 1 2 1 2 0 2 2 0 0 1 2 0 0\n",
      " 1 2 0 0 1 2 2 0 2 1 0 1 2 1 0 2 2 1 1 2 2 2 1 2 1 1 2 2 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dt_clf = DecisionTreeClassifier( )\n",
    "iris_data = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \n",
    "                                                    test_size=0.3, random_state=21)\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2cb70d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 : 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# 학습 수행\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "#예측 수행\n",
    "pred = dt_clf.predict(X_test)\n",
    "print('예측 정확도 :', accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ce274e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘파이 ndarray 뿐만 아니라 판다스 DataFrame/Series도 train_test_split()으로 분할 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fa28b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "iris_df['target'] = iris_data.target\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95287de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 데이터 프레임 반환(마지막 열 전까지, 마지막 열제외)\n",
    "feature_df = iris_df.iloc[:,:-1]\n",
    "\n",
    "# 타깃 데이터 프레임 반환\n",
    "target_df = iris_df.iloc[:,-1]\n",
    "\n",
    "\n",
    "# 학습 / 테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_df, target_df, \n",
    "                                                    test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "405f119e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72e7282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 :  0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print('예측 정확도 : ', accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9d79bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴드 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cd66e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b2d7ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기 : 150\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier 객체 생성\n",
    "dr_clf = DecisionTreeClassifier(random_state =156)\n",
    "# 5개의 폴드 세트로 분리하는 KFold객체와 폴드 세트별 정확도를 담을 리스트객체 생성\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "print('붓꽃 데이터 세트 크기 :' , features.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba58792c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-53-7d9fb6a2cea2>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-53-7d9fb6a2cea2>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    print('정확도 : %f, 학습데이터크기 : %d , 검증데이터크기: %d', %(acc,train_size,test_size))\u001b[0m\n\u001b[1;37m                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kfold.split(features):\n",
    "    X_train , X_test = features[train_index],features[test_index]\n",
    "    y_train, t_test = label[train_index],label[test_index]\n",
    "    dt_clf.fit(X_train,y_train)\n",
    "    \n",
    "    pred = dt_clf.predict(X_test)\n",
    "    acc = np.round(accuracy_score(y_test,pred),3)\n",
    "    \n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    \n",
    "    print('정확도 : %f, 학습데이터크기 : %d , 검증데이터크기: %d', %(acc,train_size,test_size))\n",
    "    \n",
    "    cv_accuracy.append(acc)\n",
    "\n",
    "print('평균 검증 정확도:',np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40a975",
   "metadata": {},
   "source": [
    "# stratified K폴드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7a3157b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "iris = load_iris()\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "08258d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[교차검증 : 1]\n",
      "학습용:  1    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증용:  0    50\n",
      "Name: label, dtype: int64\n",
      "[교차검증 : 2]\n",
      "학습용:  0    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증용:  1    50\n",
      "Name: label, dtype: int64\n",
      "[교차검증 : 3]\n",
      "학습용:  0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증용:  2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#3개 폴드를 구성\n",
    "kfold = KFold(n_splits =3)\n",
    "\n",
    "n=0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n+=1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test= iris_df['label'].iloc[test_index]\n",
    "    print('[교차검증 : %d]'%(n))\n",
    "    print('학습용: ',label_train.value_counts())\n",
    "    print('검증용: ',label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2152ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3개의 폴드 세트로 KFold 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2acb58a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-57-8e02fecaac30>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-57-8e02fecaac30>\"\u001b[1;36m, line \u001b[1;32m19\u001b[0m\n\u001b[1;33m    print('정확도 : %f, 학습데이터크기 : %d , 검증데이터크기: %d', %(accuracy,train_size,test_size))\u001b[0m\n\u001b[1;37m                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier 객체 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "kfold= KFold(n_splits=3)\n",
    "cv_accuracy=[]\n",
    "n=0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    X_train , X_test = features[train_index],features[test_index]\n",
    "    y_train, t_test = label[train_index],label[test_index]\n",
    "    \n",
    "\n",
    "    dt_clf.fit(X_train,y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n+=1\n",
    "    \n",
    "    \n",
    "    accuracy = np.round(accuracy_score(y_test,pred),3)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('정확도 : %f, 학습데이터크기 : %d , 검증데이터크기: %d', %(accuracy,train_size,test_size))\n",
    "\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "print('평균 검증 정확도 :',np.mean(cv_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8e4e16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[교차검증: %d]%n\n",
      "학습용 레이블 분포: \n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증용 레이블 분포: \n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "[교차검증: %d]%n\n",
      "학습용 레이블 분포: \n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증용 레이블 분포: \n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "[교차검증: %d]%n\n",
      "학습용 레이블 분포: \n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증용 레이블 분포: \n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n=0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n+=1\n",
    "    \n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('[교차검증: %d]%n')\n",
    "    print('학습용 레이블 분포: \\n', label_train.value_counts())\n",
    "    print('검증용 레이블 분포: \\n',label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d42c7ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [45, 50]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-fdd95a032e20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mn\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [45, 50]"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "skfold= StratifiedKFold(n_splits=3)\n",
    "cv_accuracy=[]\n",
    "n=0\n",
    "for train_index, test_index in skfold.split(features, label):\n",
    "    X_train , X_test = features[train_index],features[test_index]\n",
    "    y_train, t_test = label[train_index],label[test_index]\n",
    "    \n",
    "    #학습 및 예측\n",
    "    dt_clf.fit(X_train,y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    \n",
    "    # 반복시 마다 정확도 측정\n",
    "    n+=1\n",
    "    \n",
    "    acc = np.round(accuracy_score(y_test,pred),4)\n",
    "    \n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('%d \\n정확도 : %f, 학습데이터크기 : %d , 검증데이터크기: %d' %(n,acc,train_size,test_size))\n",
    "\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "print('평균 검증 정확도 :',np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4779ffb",
   "metadata": {},
   "source": [
    "# 붓꽃자료를 3개 폴드로 분할하여 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ec76aa93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 별 정확도: [0.98 0.94 0.98]\n",
      "평균 검증 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score , cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "\n",
    "scores = cross_val_score(dt_clf, features, label, scoring='accuracy',cv=3)\n",
    "print('교차 검증 별 정확도:',scores)\n",
    "print('평균 검증 정확도:',np.round(np.mean(scores),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce7bd14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search CV를 이용해 결정트리 알고리즘의 여러가지 최적화 파라미터를 순차적용 붓꽃 데이터 예측 분석\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=121)\n",
    "\n",
    "st_clf = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'max_depth':[1,2,3],'min_samples_split':[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fa2d7bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.110223e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>4.709208e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.110223e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3.118048e-02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.559024e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>9.989584e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3.118048e-02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.559024e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>4.720461e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>2.041241e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.178511e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>2.041241e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.178511e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.001622      0.000441         0.000000    0.000000e+00   \n",
       "1       0.001326      0.000476         0.000333    4.709208e-04   \n",
       "2       0.001051      0.000069         0.000000    0.000000e+00   \n",
       "3       0.001324      0.000459         0.000998    9.989584e-07   \n",
       "4       0.000667      0.000471         0.000668    4.720461e-04   \n",
       "5       0.000999      0.000001         0.000000    0.000000e+00   \n",
       "\n",
       "  param_max_depth param_min_samples_split  \\\n",
       "0               1                       2   \n",
       "1               1                       3   \n",
       "2               2                       2   \n",
       "3               2                       3   \n",
       "4               3                       2   \n",
       "5               3                       3   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}              0.700   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}              0.700   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}              0.925   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}              0.925   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}              0.975   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}              0.975   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0                0.7               0.70         0.700000    1.110223e-16   \n",
       "1                0.7               0.70         0.700000    1.110223e-16   \n",
       "2                1.0               0.95         0.958333    3.118048e-02   \n",
       "3                1.0               0.95         0.958333    3.118048e-02   \n",
       "4                1.0               0.95         0.975000    2.041241e-02   \n",
       "5                1.0               0.95         0.975000    2.041241e-02   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                5              0.7000              0.7000   \n",
       "1                5              0.7000              0.7000   \n",
       "2                3              0.9750              0.9375   \n",
       "3                3              0.9750              0.9375   \n",
       "4                1              0.9875              0.9625   \n",
       "5                1              0.9875              0.9625   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0              0.7000          0.700000     1.110223e-16  \n",
       "1              0.7000          0.700000     1.110223e-16  \n",
       "2              0.9625          0.958333     1.559024e-02  \n",
       "3              0.9625          0.958333     1.559024e-02  \n",
       "4              0.9875          0.979167     1.178511e-02  \n",
       "5              0.9875          0.979167     1.178511e-02  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "grid_tree=GridSearchCV(dt_clf, param_grid=parameters,cv=3,refit=True,\n",
    "                       return_train_score=True)\n",
    "grid_tree.fit(X_train,y_train)\n",
    "\n",
    "scores_df=pd.DataFrame(grid_tree.cv_results_)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea3a626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
